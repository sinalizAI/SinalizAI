"""
Controller para tela de detec√ß√£o de sinais LIBRAS usando MoViNet
"""
from camera4kivy import Preview
from utils.base_screen import BaseScreen
from kivy.graphics import Color, Line, Rectangle
from kivy.clock import Clock
import numpy as np
import cv2
import os
import tensorflow as tf
from pathlib import Path
import time
from collections import deque

# Classes de sinais LIBRAS do modelo treinado
SIGNS_CLASSES = sorted([
    'A', 'ABACAXI', 'ABANAR', 'ABANDONAR', 'ABELHA', 'ABENCOAR',
    'ABOBORA', 'ABORTO', 'ABRACO', 'ABRIR_JANELA', 'ABRIR_PORTA',
    'ACABAR', 'ANIMAL_MIMADO', 'A_NOITE_TODA', 'A_TARDE_TODA'
])

class SignsDetectionPreview(Preview):
    """Preview personalizado para captura de sequ√™ncia de frames"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.parent_screen = None
        self.current_frame = None
        
    def set_parent_screen(self, screen):
        """Define a tela pai para comunica√ß√£o"""
        self.parent_screen = screen
        
    def analyze_pixels_callback(self, pixels, image_size, image_pos, image_scale, mirror):
        """Processa frame da c√¢mera"""
        try:
            # Converte pixels RGBA para BGR OpenCV
            frame = np.frombuffer(pixels, dtype=np.uint8)
            frame = frame.reshape(image_size[1], image_size[0], 4)
            bgr = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)
            
            # Armazena frame atual
            self.current_frame = bgr
            
            # Notifica a tela pai que tem um novo frame
            if self.parent_screen:
                self.parent_screen.process_new_frame(bgr)
                
        except Exception as e:
            print(f"‚ùå Erro na captura de frame: {e}")


class SignsDetectionScreen(BaseScreen):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # Par√¢metros do modelo (baseado no modelo TFLite)
        self.FRAME_COUNT = 16
        self.HEIGHT = 172
        self.WIDTH = 172
        self.CONFIDENCE_THRESHOLD = 0.70
        
        # Par√¢metros da janela de contexto
        self.RECORDING_DURATION = 4
        self.COOLDOWN_DURATION = 3
        
        # Estados da m√°quina de estados
        self.current_state = "WAITING"
        self.recorded_frames = []
        self.recording_start_time = 0
        self.cooldown_start_time = 0
        self.prediction_result = ""
        
        # Modelo TensorFlow Lite
        self.interpreter = None
        self.input_details = None
        self.output_details = None
        self.model_loaded = False
        
        # Preview da c√¢mera
        self.preview = None
        
        # Carregar modelo
        Clock.schedule_once(self.load_model, 0.1)
    
    def load_model(self, dt):
        """Carrega o modelo TensorFlow Lite para detec√ß√£o de sinais"""
        try:
            print("üì• Iniciando carregamento do modelo TFLite...")
            
            # Caminho do modelo TensorFlow Lite
            model_path = os.path.join("services", "ml", "modelo_video.tflite")
            
            print(f"üîç Verificando arquivo: {model_path}")
            print(f"   Arquivo existe: {os.path.exists(model_path)}")
            
            if os.path.exists(model_path):
                print("ÔøΩ Carregando modelo TensorFlow Lite...")
                
                # Carrega o modelo TFLite
                self.interpreter = tf.lite.Interpreter(model_path=model_path)
                self.interpreter.allocate_tensors()
                
                # Obt√©m detalhes de entrada e sa√≠da
                self.input_details = self.interpreter.get_input_details()
                self.output_details = self.interpreter.get_output_details()
                
                print(f"‚úÖ Modelo TFLite carregado com sucesso!")
                print(f"üìä Input shape: {self.input_details[0]['shape']}")
                print(f"üìä Output shape: {self.output_details[0]['shape']}")
                print(f"üìä Input dtype: {self.input_details[0]['dtype']}")
                print(f"üìä Output dtype: {self.output_details[0]['dtype']}")
                
                self.model_loaded = True
                
                if hasattr(self, 'ids') and hasattr(self.ids, 'status_label'):
                    self.ids.status_label.text = "Modelo TFLite carregado - C√¢mera ativa"
                    
            else:
                print(f"‚ùå Modelo TFLite n√£o encontrado: {model_path}")
                self.model_loaded = False
                if hasattr(self, 'ids') and hasattr(self.ids, 'status_label'):
                    self.ids.status_label.text = "Erro: Modelo TFLite n√£o encontrado"
                    
        except Exception as e:
            print(f"‚ùå Erro no carregamento do TFLite: {e}")
            import traceback
            traceback.print_exc()
            self.model_loaded = False
            if hasattr(self, 'ids') and hasattr(self.ids, 'status_label'):
                self.ids.status_label.text = f"Erro TFLite: {str(e)[:30]}"
    
    def on_enter(self):
        """Chamado quando a tela √© exibida"""
        super().on_enter()
        print("üé¨ Entrando na tela de detec√ß√£o de sinais")
        if self.preview is None:
            self.setup_camera()
    
    def setup_camera(self):
        """Configura a c√¢mera IGUAL ao detection_controller_camera4kivy.py"""
        try:
            print("üì∑ Iniciando camera4kivy...")
            
            # Remove preview anterior se existir
            if self.preview:
                camera_display = self.ids.get('camera_layout')
                if camera_display:
                    camera_display.remove_widget(self.preview)
            
            # Cria novo preview personalizado
            self.preview = SignsDetectionPreview()
            
            # Define a tela pai no preview
            self.preview.set_parent_screen(self)
            
            # Conecta com a c√¢mera usando o mesmo m√©todo do detection.py
            Clock.schedule_once(self._connect_camera, 0.1)
            
        except Exception as e:
            print(f"‚ùå Erro ao configurar c√¢mera: {e}")
    
    def _connect_camera(self, dt):
        """Conecta a c√¢mera ao preview - IGUAL ao detection_controller_camera4kivy.py"""
        try:
            camera_display = self.ids.get('camera_layout')
            if camera_display and self.preview:
                camera_display.add_widget(self.preview)
                # Conecta com an√°lise de pixels habilitada
                self.preview.connect_camera(
                    camera_id="0", 
                    filepath_callback=None,
                    enable_analyze_pixels=True,
                    analyze_pixels_resolution=480,
                    mirror=True
                )
                print("‚úÖ Camera4kivy iniciada")
                
                # Atualiza status
                if hasattr(self, 'ids') and hasattr(self.ids, 'status_label'):
                    self.ids.status_label.text = "C√¢mera ativa - Aguardando sinal"
                
            else:
                print("‚ùå Erro: camera_layout n√£o encontrado")
                
        except Exception as e:
            print(f"‚ùå Erro ao conectar c√¢mera: {e}")
    
    def hide_instructions(self):
        """Esconde o card de instru√ß√µes"""
        try:
            instruction_card = self.ids.get('instruction_card')
            if instruction_card:
                # Remove o card das instru√ß√µes
                instruction_card.parent.remove_widget(instruction_card)
                print("‚úÖ Instru√ß√µes removidas")
        except Exception as e:
            print(f"‚ùå Erro ao remover instru√ß√µes: {e}")
    
    def process_new_frame(self, frame):
        """Processa novo frame da c√¢mera (chamado pelo preview)"""
        if not self.model_loaded:
            return
        
        try:
            # Atualiza a m√°quina de estados
            self.update_state_machine(frame)
            
        except Exception as e:
            print(f"‚ùå Erro no processamento do frame: {e}")
    
    def preprocess_frame(self, frame, image_size=(172, 172)):
        """Pr√©-processa um √∫nico frame da webcam (baseado no teste_janela.py)"""
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_tf = tf.image.convert_image_dtype(frame_rgb, tf.float32)
        frame_resized = tf.image.resize_with_pad(frame_tf, image_size[0], image_size[1])
        return frame_resized
    
    def process_frame(self, dt):
        """Processa frame da c√¢mera em tempo real"""
        if not self.preview or not self.model_loaded:
            return
        
        try:
            # Captura o frame atual da preview
            frame = self.preview.get_frame()
            if frame is None:
                return
            
            # Se o frame for uma texture, converte para numpy array
            if hasattr(frame, 'get_region'):
                # √â uma texture, precisa converter
                import io
                frame_bytes = io.BytesIO()
                frame.save(frame_bytes, fmt='png')
                frame_bytes.seek(0)
                frame_array = np.frombuffer(frame_bytes.getvalue(), dtype=np.uint8)
                frame = cv2.imdecode(frame_array, cv2.IMREAD_COLOR)
            elif isinstance(frame, bytes):
                # Frame em bytes
                frame_array = np.frombuffer(frame, dtype=np.uint8)
                frame = cv2.imdecode(frame_array, cv2.IMREAD_COLOR)
            
            if frame is not None:
                # Atualiza a m√°quina de estados
                self.update_state_machine(frame)
                
        except Exception as e:
            print(f"Erro no processamento do frame: {e}")
            # Tenta m√©todo alternativo de captura
            self.fallback_frame_capture()
    
    def fallback_frame_capture(self):
        """M√©todo alternativo de captura de frames se o principal falhar"""
        try:
            # Usa OpenCV diretamente como backup
            if not hasattr(self, 'backup_cap'):
                self.backup_cap = cv2.VideoCapture(0)
            
            ret, frame = self.backup_cap.read()
            if ret and frame is not None:
                self.update_state_machine(frame)
        except Exception as e:
            print(f"Erro no m√©todo de backup: {e}")
    
    def preprocess_frame(self, frame, image_size=(172, 172)):
        """Pr√©-processa um √∫nico frame da webcam com melhor gerenciamento de mem√≥ria"""
        try:
            # Valida se o frame √© v√°lido
            if frame is None or frame.size == 0:
                return None
                
            # Converte para RGB usando NumPy (mais est√°vel)
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            
            # Redimensiona usando OpenCV (mais eficiente)
            frame_resized = cv2.resize(frame_rgb, image_size, interpolation=cv2.INTER_AREA)
            
            # Normaliza para [0, 1]
            frame_normalized = frame_resized.astype(np.float32) / 255.0
            
            return frame_normalized
            
        except Exception as e:
            print(f"‚ùå Erro no pr√©-processamento: {e}")
            return None
    
    def update_state_machine(self, frame):
        """Atualiza a m√°quina de estados de grava√ß√£o e predi√ß√£o com melhor controle"""
        if frame is None:
            return
            
        current_time = time.time()
        
        if self.current_state == "WAITING":
            # Atualiza status apenas se necess√°rio
            if hasattr(self, 'ids') and hasattr(self.ids, 'status_label'):
                if "Pressione 'REC'" not in self.ids.status_label.text:
                    self.ids.status_label.text = f"Pressione 'REC' para iniciar grava√ß√£o"
        
        elif self.current_state == "RECORDING":
            elapsed = current_time - self.recording_start_time
            countdown = self.RECORDING_DURATION - elapsed
            
            if hasattr(self, 'ids') and hasattr(self.ids, 'status_label'):
                self.ids.status_label.text = f"GRAVANDO... {int(countdown)+1}s"
            
            # Processa e armazena o frame (COM LIMITE)
            if len(self.recorded_frames) < 100:  # Limite m√°ximo de frames
                try:
                    processed_frame = self.preprocess_frame(frame)
                    if processed_frame is not None:
                        self.recorded_frames.append(processed_frame)
                        print(f"üìπ Frame {len(self.recorded_frames)} capturado")
                except Exception as e:
                    print(f"‚ùå Erro ao processar frame: {e}")
            
            if elapsed >= self.RECORDING_DURATION:
                print(f"‚è±Ô∏è Grava√ß√£o finalizada. {len(self.recorded_frames)} frames capturados")
                self.current_state = "PROCESSING"
        
        elif self.current_state == "PROCESSING":
            if hasattr(self, 'ids') and hasattr(self.ids, 'status_label'):
                self.ids.status_label.text = "Processando..."
            
            if len(self.recorded_frames) >= self.FRAME_COUNT and self.model:
                try:
                    print(f"üîÆ Processando {len(self.recorded_frames)} frames...")
                    
                    # Seleciona frames uniformemente espa√ßados
                    indices = np.linspace(0, len(self.recorded_frames) - 1, self.FRAME_COUNT, dtype=int)
                    sequence_to_predict = [self.recorded_frames[i] for i in indices]
                    
                    # Cria tensor de entrada com valida√ß√£o de shape
                    input_array = np.array(sequence_to_predict, dtype=np.float32)
                    input_tensor = np.expand_dims(input_array, axis=0)
                    
                    print(f"üìä Shape do tensor: {input_tensor.shape}")
                    
                    # Valida shape antes da predi√ß√£o
                    expected_shape = (1, self.FRAME_COUNT, self.HEIGHT, self.WIDTH, 3)
                    if input_tensor.shape != expected_shape:
                        print(f"‚ùå Shape incorreto: esperado {expected_shape}, obtido {input_tensor.shape}")
                        self.prediction_result = "Erro: Shape incorreto"
                    else:
                        # SOLU√á√ÉO RADICAL: Executa predi√ß√£o em processo separado para evitar crash
                        try:
                            print(f"üîß Salvando dados para predi√ß√£o isolada...")
                            
                            # Salva o tensor em arquivo tempor√°rio
                            import tempfile
                            import pickle
                            
                            with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as temp_file:
                                pickle.dump(input_tensor, temp_file)
                                temp_path = temp_file.name
                            
                            print(f"üìÅ Dados salvos em: {temp_path}")
                            
                            # Executa predi√ß√£o em processo separado usando subprocess
                            import subprocess
                            import sys
                            
                            # Script de predi√ß√£o isolado
                            prediction_script = f'''
import os
os.chdir("{os.getcwd()}/services/ml")
import tensorflow as tf
import numpy as np
import pickle

# Configura√ß√µes seguras
tf.config.set_soft_device_placement(True)

try:
    # Carrega dados
    with open("{temp_path}", "rb") as f:
        input_tensor = pickle.load(f)
    
    # Carrega modelo
    model = tf.keras.models.load_model("movinet_libras_final_base.keras", compile=False)
    
    # Predi√ß√£o
    predictions = model.predict(input_tensor, verbose=0, batch_size=1)
    predicted_index = int(np.argmax(predictions[0]))
    confidence = float(predictions[0][predicted_index])
    
    print(f"{{predicted_index}},{{confidence}}")
    
except Exception as e:
    print(f"ERROR:{{e}}")
finally:
    # Remove arquivo tempor√°rio
    try:
        os.unlink("{temp_path}")
    except:
        pass
'''
                            
                            # Executa em processo separado
                            result = subprocess.run(
                                [sys.executable, "-c", prediction_script],
                                capture_output=True,
                                text=True,
                                timeout=30  # Timeout de 30 segundos
                            )
                            
                            print(f"üîç Resultado do processo: {result.stdout.strip()}")
                            
                            if result.returncode == 0 and "," in result.stdout:
                                # Parse do resultado
                                output_line = result.stdout.strip().split('\n')[-1]
                                if "," in output_line and not output_line.startswith("ERROR:"):
                                    predicted_index, confidence = output_line.split(',')
                                    predicted_index = int(predicted_index)
                                    confidence = float(confidence)
                                    
                                    print(f"üéØ Predi√ß√£o: √≠ndice={predicted_index}, confian√ßa={confidence:.3f}")
                                    
                                    if confidence > self.CONFIDENCE_THRESHOLD:
                                        predicted_class = SIGNS_CLASSES[predicted_index]
                                        self.prediction_result = f"{predicted_class} ({confidence:.2f})"
                                        print(f"‚úÖ Resultado: {self.prediction_result}")
                                    else:
                                        self.prediction_result = "N√£o identificado"
                                        print(f"‚ùå Confian√ßa baixa: {confidence:.3f}")
                                else:
                                    self.prediction_result = "Erro no processo"
                                    print(f"‚ùå Sa√≠da inv√°lida: {result.stdout}")
                            else:
                                self.prediction_result = "Erro no processo"
                                print(f"‚ùå Processo falhou: {result.stderr}")
                                
                        except subprocess.TimeoutExpired:
                            print(f"‚ùå Timeout na predi√ß√£o")
                            self.prediction_result = "Timeout na predi√ß√£o"
                        except Exception as process_error:
                            print(f"‚ùå Erro no processo: {process_error}")
                            import traceback
                            traceback.print_exc()
                            self.prediction_result = "Erro no processo"
                        finally:
                            # Limpa arquivo tempor√°rio se ainda existir
                            try:
                                if 'temp_path' in locals():
                                    os.unlink(temp_path)
                            except:
                                pass
                        
                except Exception as pred_error:
                    print(f"‚ùå Erro na predi√ß√£o: {pred_error}")
                    self.prediction_result = "Erro na predi√ß√£o"
                finally:
                    # LIMPA MEM√ìRIA ap√≥s processamento
                    self.recorded_frames.clear()
                    import gc
                    gc.collect()
            else:
                self.prediction_result = "Poucos frames gravados"
                print(f"‚ùå Poucos frames: {len(self.recorded_frames)}/{self.FRAME_COUNT}")

            self.current_state = "COOLDOWN"
            self.cooldown_start_time = current_time
                
        elif self.current_state == "COOLDOWN":
            elapsed = current_time - self.cooldown_start_time
            
            if hasattr(self, 'ids') and hasattr(self.ids, 'status_label'):
                self.ids.status_label.text = f"Resultado: {self.prediction_result}"
            if hasattr(self, 'ids') and hasattr(self.ids, 'result_label'):
                self.ids.result_label.text = self.prediction_result
            
            if elapsed >= self.COOLDOWN_DURATION:
                self.current_state = "WAITING"
                if hasattr(self, 'ids') and hasattr(self.ids, 'result_label'):
                    self.ids.result_label.text = ""
                print("üîÑ Pronto para nova grava√ß√£o")
    
    def start_recording(self):
        """Inicia a grava√ß√£o"""
        if not self.model_loaded:
            print("‚ö†Ô∏è Modelo n√£o carregado, n√£o √© poss√≠vel gravar")
            if hasattr(self, 'ids') and hasattr(self.ids, 'status_label'):
                self.ids.status_label.text = "Erro: Modelo n√£o carregado"
            return
            
        if self.current_state == "WAITING":
            print("üé¨ Iniciando grava√ß√£o...")
            self.current_state = "RECORDING"
            self.recorded_frames = []
            self.recording_start_time = time.time()
        else:
            print(f"‚ö†Ô∏è N√£o √© poss√≠vel gravar no estado atual: {self.current_state}")
    
    def start_manual_recording(self):
        """Inicia grava√ß√£o manual atrav√©s do bot√£o REC"""
        self.start_recording()
    
    def on_leave(self):
        """Chamado quando sai da tela"""
        super().on_leave()
        print("üìπ Saindo da detec√ß√£o de sinais...")
        
        # Remove a c√¢mera
        if self.preview:
            try:
                self.ids.camera_layout.remove_widget(self.preview)
                self.preview = None
                print("üìπ C√¢mera desconectada")
            except:
                pass
    
    def go_back(self):
        """Volta para a tela anterior"""
        print("üè† Voltando para home...")
        self.manager.current = 'home'